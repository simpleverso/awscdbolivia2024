{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017144b3-32e8-4541-a137-d06de4a0fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actualizar version de boto3 y reiniciar kernel\n",
    "!pip install boto3 botocore aiobotocore --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7ed4f5-173a-4224-8169-813557988d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instrucciones usando invoke model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e14020ee-e0a0-4e96-8433-e05348177217",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hi! I am very well thank you, how about you?\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "# Cambia el model_id para usar diferentes modelos\n",
    "model_id = 'meta.llama2-13b-chat-v1' \n",
    "#model_id = 'mistral.mistral-large-2402-v1:0'\n",
    "#model_id = 'cohere.command-text-v14'\n",
    "\n",
    "prompt = \"Human: Hola que tal, como estas? \"\n",
    "\n",
    "if model_id.startswith('cohere'):\n",
    "    input = {'prompt': prompt+\" provide your response in english no mather the input language\", 'stop_sequences': [\"\\n\"], 'max_tokens': 200,'temperature': 0.5}     # Si el modelo es de Cohere\n",
    "elif model_id.startswith('mistral'):\n",
    "    input = {'prompt': prompt.replace(\"Human\", \"'role': 'user'\"), 'stop': [\"\\n\"], 'temperature': 0.5}     # Si el modelo es de Mistral \n",
    "elif model_id.startswith('meta'):\n",
    "    input = {'prompt': prompt.replace(\"Human\",\"<s>[INST] {\")+\" proporciona tu respuesta en espaniol\"+\"prompt} [/INST]\",'max_gen_len': 200,'temperature': 0.5}     # Si el modelo es de Meta \n",
    "\n",
    "# Enviar solicitud al modelo seleccionado\n",
    "body = json.dumps(input)\n",
    "response = bedrock.invoke_model(body=body, modelId=model_id)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "# Imprimir las generaciones para los diferentes modelos\n",
    "if model_id.startswith('cohere') or model_id.startswith('mistral'):\n",
    "    completions = response_body.get('generations', response_body.get('outputs', []))\n",
    "    for part in completions:\n",
    "        print(part['text'])\n",
    "else:\n",
    "    print(response_body['generation'])\n",
    "    \n",
    "    #https://docs.aws.amazon.com/bedrock/latest/userguide/bedrock-runtime_example_bedrock-runtime_InvokeModelWithResponseStream_MetaLlama2_section.html\n",
    "    #https://docs.aws.amazon.com/bedrock/latest/userguide/bedrock-runtime_example_bedrock-runtime_InvokeModel_CohereCommand_section.html\n",
    "    #https://docs.aws.amazon.com/bedrock/latest/userguide/bedrock-runtime_example_bedrock-runtime_InvokeModel_MistralAi_section.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4f7dd1-7889-41c1-ae82-d15018c3e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chat usando invoke model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "38cf9d6c-8489-4c16-9997-3878849f6df6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm sorry, I can only help you in English now. If you're missing your cat, you could try checking the most likely spots where it might hide, such as small spaces, behind furniture, or near its food or water bowl. You could also try calling out its name to see if it responds, or use treats to coax it out of its hiding spot. It's also a good idea to ensure all doors and windows are closed to prevent your cat from accidentally escaping. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "# Cambia el model_id para usar diferentes modelos\n",
    "model_id = 'meta.llama2-13b-chat-v1' \n",
    "#model_id = 'mistral.mistral-large-2402-v1:0'\n",
    "#model_id = 'cohere.command-text-v14'\n",
    "\n",
    "#contexto\n",
    "prompt = \"\"\"\n",
    "Human: Hola que tal, como estas?\n",
    "AI: Hola, estoy bien, como te encuentras tu?\n",
    "Human: No puedo encontrar a mi gato.\n",
    "AI: Lamento escuchar eso. Yo puedo ayudarte a encontrar a tu gato.\n",
    "Human: Gracias! donde crees que se pueda esconder?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "if model_id.startswith('cohere'):\n",
    "    input = {'prompt': prompt+\" provide your response in english no mather the input language\", 'stop_sequences': [\"\\n\"], 'max_tokens': 200,'temperature': 0.5}     # Si el modelo es de Cohere\n",
    "elif model_id.startswith('mistral'):\n",
    "    input = {'prompt': prompt.replace(\"Human\", \"'role': 'user'\"), 'stop': [\"\\n\"], 'temperature': 0.5}     # Si el modelo es de Mistral \n",
    "elif model_id.startswith('meta'):\n",
    "    input = {'prompt': prompt.replace(\"Human\",\"<s>[INST] {\")+\" proporciona tu respuesta en espaniol\"+\"prompt} [/INST]\",'max_gen_len': 200,'temperature': 0.5}     # Si el modelo es de Meta \n",
    "\n",
    "# Enviar solicitud al modelo seleccionado\n",
    "body = json.dumps(input)\n",
    "response = bedrock.invoke_model(body=body, modelId=model_id)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "# Imprimir las generaciones para los diferentes modelos\n",
    "if model_id.startswith('cohere') or model_id.startswith('mistral'):\n",
    "    completions = response_body.get('generations', response_body.get('outputs', []))\n",
    "    for part in completions:\n",
    "        print(part['text'])\n",
    "else:\n",
    "    print(response_body['generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41507139-84ac-4f99-ab06-cc3086799eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instruccion usando bedrock converse api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b14bb45-ee87-4975-9bf3-5524a913263e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I'm doing well, thank you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "#model_id = 'amazon.titan-text-lite-v1'\n",
    "#model_id = 'meta.llama2-13b-chat-v1' \n",
    "#model_id = 'mistral.mistral-large-2402-v1:0'\n",
    "bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "messages = [\n",
    "    {\"role\": \"user\",      \"content\": [{\"text\": \"Hola, como estas?\"}]}\n",
    "]\n",
    "inference_config = {\"temperature\": 0.5, \"maxTokens\": 200, \"stopSequences\": []}\n",
    "response = bedrock.converse(\n",
    "    modelId=model_id,\n",
    "    messages=messages,\n",
    "    inferenceConfig=inference_config\n",
    ")\n",
    "content = response['output']['message']['content']\n",
    "for item in content:\n",
    "    print(item['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ea54e2-322b-4e11-a1cc-6b0a0b5a5f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chat usando bedrock converse api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62f62600-1867-4465-934c-ec84238044a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si es un gato callejero, podría estar en un árbol o en un arbusto. También podría estar en un garaje o en un patio trasero.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "model_id = 'amazon.titan-text-lite-v1'\n",
    "#model_id = 'meta.llama2-13b-chat-v1' \n",
    "#model_id = 'mistral.mistral-large-2402-v1:0'\n",
    "\n",
    "bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "messages = [\n",
    "    {\"role\": \"user\",           \"content\": [{\"text\": \"Hola, como estas?\"}]},\n",
    "    {\"role\": \"assistant\",      \"content\": [{\"text\": \"Hola, estoy bien, como te encuentras tu?\"}]},\n",
    "    {\"role\": \"user\",           \"content\": [{\"text\": \"No puedo encontrar a mi gato.\"}]},\n",
    "    {\"role\": \"assistant\",      \"content\": [{\"text\": \"Lamento escuchar eso. Yo puedo ayudarte a encontrar a tu gato.\"}]},\n",
    "    {\"role\": \"user\",           \"content\": [{\"text\": \"Gracias! donde crees que se pueda esconder?\"}]},\n",
    "]\n",
    "\n",
    "response = bedrock.converse(\n",
    "    modelId=model_id,\n",
    "    messages=messages,\n",
    "    inferenceConfig={\"temperature\": 0.5, \"maxTokens\": 200, \"stopSequences\": []}\n",
    ")\n",
    "content = response['output']['message']['content']\n",
    "for item in content:\n",
    "    print(item['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce81bbe-63a6-4ba4-aec0-0be9aba39b17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
